Cross-validation (CV) is a popular method for model-selection.  Unfortunately, it is not immediately obvious how to apply CV to unsupervised or exploratory contexts.  This thesis discusses some extensions of cross-validation to unsupervised learning, specifically focusing on the problem of choosing how many principal components to keep.  We introduce the latent factor model, define an objective criterion, and show how CV can be used to estimate the intrinsic dimensionality of a data set.  Through both simulation and theory, we demonstrate that cross-validation is a valuable tool for unsupervised learning.

